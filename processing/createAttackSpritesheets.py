#!/usr/bin/env python3
"""Create spritesheets from attack animation PNG files with JSON metadata."""

import hashlib
import json
import math
import subprocess
import sys
from pathlib import Path
from PIL import Image

DEFAULT_FRAME_SIZE = 96

# Special case: files with non-standard frame sizes (source_size, output_size)
# If only one value, it's used for both source and output
SPECIAL_FRAME_SIZES = {
    "stat_boost_player": (106, 106),
    "stat_debuff_player": (128, 106),  # Source 128, cropped to 106
}

# Special case: files that need cropping (top, right, bottom, left) - applied before flip
FRAME_CROP = {
    "stat_debuff_player": (22, 11, 0, 11),  # Crop 128x128 to 106x106
}

# Special case: gachachacha variants share many frames
GACHACHACHA_VARIANTS = ["gachachacha_bunnies", "gachachacha_carrots", "gachachacha_skulls"]

# Special case: files that need vertical flip applied to each frame
VERTICAL_FLIP_FILES = {"stat_boost_enemy", "stat_debuff_player"}

# Output files to exclude from input scanning
OUTPUT_FILES = {"attack_spritesheet.png", "attack_spritesheet_106.png"}


def find_valid_attack_pngs(directory: str) -> list[tuple[str, int, int, int, int]]:
    """Find all PNG files whose dimensions are evenly divisible by their frame size.

    Returns list of (path, cols, rows, source_frame_size, output_frame_size) tuples.
    """
    result = []
    for f in sorted(Path(directory).glob("*.png")):
        if f.name in OUTPUT_FILES:
            continue
        try:
            name = f.stem
            size_info = SPECIAL_FRAME_SIZES.get(name)
            if size_info:
                source_size, output_size = size_info
            else:
                source_size = output_size = DEFAULT_FRAME_SIZE
            with Image.open(f) as img:
                w, h = img.size
                if w % source_size == 0 and h % source_size == 0:
                    cols = w // source_size
                    rows = h // source_size
                    result.append((str(f), cols, rows, source_size, output_size))
                else:
                    print(f"âš  Skipping {f.name}: {w}x{h} not divisible by {source_size}")
        except Exception as e:
            print(f"Warning: Could not read {f}: {e}")
    return result


def extract_frames_from_spritesheet(
    png_path: str, cols: int, rows: int, frame_size: int = DEFAULT_FRAME_SIZE,
    crop: tuple[int, int, int, int] | None = None, vertical_flip: bool = False
) -> list[Image.Image]:
    """Extract all frames from a spritesheet PNG (left-to-right, top-to-bottom).

    Args:
        crop: Optional (top, right, bottom, left) pixels to crop from each frame.
              Applied before vertical flip.
    """
    frames = []
    with Image.open(png_path) as img:
        img = img.convert('RGBA')
        for row in range(rows):
            for col in range(cols):
                x = col * frame_size
                y = row * frame_size
                frame = img.crop((x, y, x + frame_size, y + frame_size))
                if crop:
                    top, right, bottom, left = crop
                    frame = frame.crop((left, top, frame_size - right, frame_size - bottom))
                if vertical_flip:
                    frame = frame.transpose(Image.FLIP_TOP_BOTTOM)
                frames.append(frame.copy())
    return frames


def frame_hash(frame: Image.Image) -> str:
    """Compute a hash for a frame to detect duplicates."""
    return hashlib.md5(frame.tobytes()).hexdigest()


def process_gachachacha_variants(
    variant_data: list[tuple[str, int, int, int]]
) -> tuple[list[Image.Image], dict[str, list[int]]]:
    """Process gachachacha variants, deduplicating shared frames.

    Returns:
        - List of unique frames (shared frames first, then unique frames per variant)
        - Dict mapping variant name to list of frame indices
    """
    # Extract frames from all variants
    variant_frames: dict[str, list[Image.Image]] = {}
    for png_path, cols, rows, source_size in variant_data:
        name = Path(png_path).stem
        variant_frames[name] = extract_frames_from_spritesheet(png_path, cols, rows, source_size)
        print(f"Extracted {len(variant_frames[name])} frames from {Path(png_path).name} ({cols}x{rows} grid)")

    # All variants should have same frame count
    frame_count = len(next(iter(variant_frames.values())))
    variant_names = list(variant_frames.keys())

    # Identify shared vs unique frames by comparing hashes
    unique_frames: list[Image.Image] = []
    frame_hash_to_index: dict[str, int] = {}
    variant_indices: dict[str, list[int]] = {name: [] for name in variant_names}

    for frame_idx in range(frame_count):
        # Get frames and hashes for this position across all variants
        frames_at_pos = [(name, variant_frames[name][frame_idx]) for name in variant_names]
        hashes_at_pos = [(name, frame_hash(frame)) for name, frame in frames_at_pos]

        # Check if all variants have the same frame at this position
        all_same = len(set(h for _, h in hashes_at_pos)) == 1

        if all_same:
            # Shared frame - use first variant's frame, reuse index for all
            h = hashes_at_pos[0][1]
            if h not in frame_hash_to_index:
                frame_hash_to_index[h] = len(unique_frames)
                unique_frames.append(frames_at_pos[0][1])
            idx = frame_hash_to_index[h]
            for name in variant_names:
                variant_indices[name].append(idx)
        else:
            # Different frames - add each variant's unique frame
            for name, frame in frames_at_pos:
                h = frame_hash(frame)
                if h not in frame_hash_to_index:
                    frame_hash_to_index[h] = len(unique_frames)
                    unique_frames.append(frame)
                variant_indices[name].append(frame_hash_to_index[h])

    total_original = frame_count * len(variant_names)
    print(f"  â†’ Deduplicated: {total_original} frames -> {len(unique_frames)} unique frames")

    return unique_frames, variant_indices


def build_spritesheet(frames: list[Image.Image], frame_size: int) -> tuple[Image.Image, list[tuple[int, int]]]:
    """Create spritesheet image and return frame positions."""
    cols = math.ceil(math.sqrt(len(frames)))
    rows = math.ceil(len(frames) / cols)
    sheet = Image.new('RGBA', (cols * frame_size, rows * frame_size), (0, 0, 0, 0))
    positions = []
    for i, frame in enumerate(frames):
        x, y = (i % cols) * frame_size, (i // cols) * frame_size
        sheet.paste(frame, (x, y))
        positions.append((x, y))
    return sheet, positions


def run_oxipng(png_path: Path) -> None:
    """Run oxipng compression on a PNG file."""
    try:
        result = subprocess.run(
            ["oxipng", "-o", "6", "--strip", "safe", str(png_path)],
            capture_output=True,
            text=True,
            timeout=300
        )
        if result.returncode == 0:
            print(f"  âœ“ Compressed with oxipng")
        else:
            print(f"  âš  oxipng warning (non-zero exit): {result.returncode}")
    except FileNotFoundError:
        print(f"  âš  oxipng not found, skipping compression")
    except subprocess.TimeoutExpired:
        print(f"  âš  oxipng timed out")
    except Exception as e:
        print(f"  âš  oxipng error: {e}")


def save_and_compress_png(sheet: Image.Image, path: Path, description: str) -> None:
    """Save a PNG and run oxipng compression on it."""
    sheet.save(path, "PNG")
    print(f"âœ… {description} saved: {sheet.size[0]}x{sheet.size[1]} -> {path}")
    run_oxipng(path)


def compact_json(obj, indent=2):
    """JSON with objects indented but all arrays inline."""
    def format_value(v, level):
        if isinstance(v, dict):
            if not v:
                return '{}'
            items = []
            for k, val in v.items():
                items.append(' ' * (level + indent) + json.dumps(k) + ': ' + format_value(val, level + indent))
            return '{\n' + ',\n'.join(items) + '\n' + ' ' * level + '}'
        elif isinstance(v, list):
            return json.dumps(v)
        else:
            return json.dumps(v)
    return format_value(obj, 0)


def create_attack_spritesheets(png_files: list[tuple[str, int, int, int, int]], output_dir: str):
    """Create combined attack spritesheet with metadata."""
    output_path = Path(output_dir)

    # Load existing JSON to preserve msPerFrame values
    json_path = output_path / "attack_spritesheet.json"
    existing_metadata = {}
    if json_path.exists():
        try:
            existing_metadata = json.loads(json_path.read_text())
            print(f"ðŸ“– Loaded existing metadata from {json_path}")
        except Exception as e:
            print(f"âš  Could not load existing JSON: {e}")

    # Group files by OUTPUT frame size (after cropping)
    files_by_size: dict[int, list[tuple[str, int, int, int]]] = {}
    for png_path, cols, rows, source_size, output_size in png_files:
        if output_size not in files_by_size:
            files_by_size[output_size] = []
        files_by_size[output_size].append((png_path, cols, rows, source_size))

    metadata = {}

    # Determine munch output location
    base_path = Path(__file__).parent
    game_dir = base_path.parent.parent
    munch_assets_dir = game_dir / "munch" / "src" / "assets" / "attacks"

    # Process each frame size group
    for output_size, size_files in sorted(files_by_size.items()):
        print(f"\n{'=' * 50}")
        print(f"Processing {output_size}x{output_size} frames...")
        print(f"{'=' * 50}")

        all_frames = []
        size_metadata = {}

        # Separate gachachacha variants from regular files
        gachachacha_files = []
        regular_files = []
        for png_path, cols, rows, source_size in size_files:
            name = Path(png_path).stem
            if name in GACHACHACHA_VARIANTS:
                gachachacha_files.append((png_path, cols, rows, source_size))
            else:
                regular_files.append((png_path, cols, rows, source_size))

        # Process regular files
        for png_path, cols, rows, source_size in regular_files:
            name = Path(png_path).stem
            vertical_flip = name in VERTICAL_FLIP_FILES
            crop = FRAME_CROP.get(name)
            frames = extract_frames_from_spritesheet(png_path, cols, rows, source_size, crop, vertical_flip)
            flip_note = " (flipped)" if vertical_flip else ""
            crop_note = " (cropped)" if crop else ""
            print(f"Extracted {len(frames)} frames from {Path(png_path).name} ({cols}x{rows} grid){crop_note}{flip_note}")

            frame_start = len(all_frames)
            all_frames.extend(frames)
            size_metadata[name] = {"_start": frame_start, "_count": len(frames), "_size": output_size}

        # Process gachachacha variants with deduplication
        if gachachacha_files:
            print(f"\nProcessing gachachacha variants with deduplication...")
            gacha_frames, gacha_indices = process_gachachacha_variants(gachachacha_files)
            gacha_frame_start = len(all_frames)
            all_frames.extend(gacha_frames)

            # Store indices (will be converted to positions later)
            for name, indices in gacha_indices.items():
                size_metadata[name] = {"_gacha_start": gacha_frame_start, "_gacha_indices": indices, "_size": output_size}

        if not all_frames:
            print(f"No frames extracted for {output_size}x{output_size}!")
            continue

        # Build spritesheet for this frame size
        sheet, positions = build_spritesheet(all_frames, output_size)

        # Determine output filename
        if output_size == DEFAULT_FRAME_SIZE:
            sheet_filename = "attack_spritesheet.png"
        else:
            sheet_filename = f"attack_spritesheet_{output_size}.png"

        sheet_path = output_path / sheet_filename
        save_and_compress_png(sheet, sheet_path, f"Attack spritesheet ({output_size}px)")

        # Copy to munch if directory exists
        if munch_assets_dir.exists():
            print(f"\nðŸ“‹ Copying to munch repository: {munch_assets_dir}")
            munch_sheet_path = munch_assets_dir / sheet_filename
            save_and_compress_png(sheet, munch_sheet_path, f"Munch attack spritesheet ({output_size}px)")

        # Finalize metadata - convert internal indices to actual positions
        for name, data in size_metadata.items():
            anim_size = data.pop("_size")
            # Get existing msPerFrame or use default
            existing_ms = existing_metadata.get(name, {}).get("msPerFrame", 100)

            if "_start" in data:
                # Regular attack
                start, count = data.pop("_start"), data.pop("_count")
                data["msPerFrame"] = existing_ms
                data["width"] = anim_size
                data["height"] = anim_size
                data["frames"] = [list(positions[start + i]) for i in range(count)]
            elif "_gacha_start" in data:
                # Gachachacha variant - use deduplicated indices
                gacha_start = data.pop("_gacha_start")
                indices = data.pop("_gacha_indices")
                data["msPerFrame"] = existing_ms
                data["width"] = anim_size
                data["height"] = anim_size
                data["frames"] = [list(positions[gacha_start + idx]) for idx in indices]

        metadata.update(size_metadata)

    if not munch_assets_dir.exists():
        print(f"\nâš  Munch directory not found, skipping copy: {munch_assets_dir}")

    # Save JSON
    json_path.write_text(compact_json(metadata))
    print(f"\nâœ… Metadata saved to: {json_path}")


def main():
    if len(sys.argv) < 2:
        print("Usage: python createAttackSpritesheets.py <target_directory>")
        sys.exit(1)

    target_dir = sys.argv[1]
    if not Path(target_dir).is_dir():
        print(f"Error: Directory '{target_dir}' does not exist")
        sys.exit(1)

    print(f"Searching for attack PNG files in: {target_dir}\n")
    png_files = find_valid_attack_pngs(target_dir)

    if not png_files:
        print("No valid attack PNG files found (dimensions must be divisible by frame size)")
        sys.exit(1)

    print(f"\nFound {len(png_files)} valid PNG files:")
    for png_path, cols, rows, source_size, output_size in png_files:
        size_info = f"{source_size}â†’{output_size}px" if source_size != output_size else f"{output_size}px"
        print(f"  - {Path(png_path).name} ({cols}x{rows} = {cols * rows} frames @ {size_info})")

    create_attack_spritesheets(png_files, target_dir)
    print("\nâœ… Done!")


if __name__ == "__main__":
    main()

